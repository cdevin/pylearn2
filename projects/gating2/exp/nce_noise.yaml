!obj:pylearn2.train.Train {
    dataset: &train !obj:noisylearn.projects.gating2.dataset.NoiseDataset {
            dataset: !obj:pylearn2.sandbox.nlp.datasets.penntree.PennTreebank {
                which_set: 'train',
                context_len: &context_len 5
            },
            noise_p: &noise_p !pkl: 'penntree_unigram.npy',
            num_noise: &num_noise 10,
    },
    model: !obj:noisylearn.projects.gating2.vLBL_NCE {
        batch_size: &batch_size 200,
        noise_p: *noise_p,
        dict_size: 10000,
        dim: 100,
        context_length: *context_len,
        k: *num_noise,
        max_col_norm: 10,
        y_max_col_norm: 10,
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        batch_size: *batch_size,
        train_iteration_mode: 'even_shuffled_sequential',
        monitor_iteration_mode: 'even_shuffled_sequential',
        learning_rate: 1.,
        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {
            init_momentum: .5,
        },
        #monitoring_dataset:
            #{
                #'train' : *train,
                #'valid' : !obj:pylearn2.sandbox.nlp.datasets.penntree.PennTreebank {
                        #which_set: 'valid',
                        #context_len: *context_len
                #},
                #'test' : !obj:pylearn2.sandbox.nlp.datasets.penntree.PennTreebank {
                        #which_set: 'test',
                        #context_len: *context_len
                #},
            #},
        #cost: !obj:noisylearn.projects.gating2.cost.NCE {}
        #cost: !obj:pylearn2.costs.mlp.Default {},
        cost: !obj:noisylearn.projects.gating2.cost.NCE_Noise {},
        #termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {
            #channel_name: "valid_y_perplexity",
            #prop_decrease: 0,
            #N: 100
        #},
        termination_criterion: !obj:pylearn2.termination_criteria.EpochCounter {
            max_epochs: 1
        },
        #update_callbacks: !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {
            #decay_factor: 1.00004,
            #min_lr: 0.00001,
        #},
    },
    extensions: [
        #!obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             #channel_name: 'valid_perplexity',
             #save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}_best.pkl"
        #},
        !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {
            start: 1,
            saturate: 50,
            final_momentum: 0.7
        },
        !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {
            start: 1,
            saturate: 100,
            decay_factor: 0.000001
        },

    ],
    #save_path: "last.pkl",
    save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl",
    save_freq: 1
}
