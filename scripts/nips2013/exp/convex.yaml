!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.icml07.Convex {
        which_set: "train",
        one_hot: 1,
    },
    model: !obj:galatea.dbm.inpaint.super_dbm.SpeedMonitoringDBM {
        inference_procedure: !obj:galatea.dbm.inpaint.super_dbm.MoreConsistent {},
              batch_size : 100,
              niter: 7, #note: since we have to backprop through the whole thing, this does
                         #increase the memory usage
              visible_layer: !obj:galatea.dbm.inpaint.super_dbm.BinaryVisLayer {
                learn_init_inpainting_state: 1,
                nvis: 784,
                bias_from_marginals: *train,
                center: 0,
              },
              hidden_layers: [
                !obj:galatea.dbm.inpaint.super_dbm.DenseMaxPool {
                    center: 0,
                        max_col_norm: 3.935500,
                        detector_layer_dim: %(layer0_dim)i,
                        pool_size: 1,
                        irange: 0.0293161770456,
                        layer_name: 'h0',
                        init_bias: -2.421949
               },
                !obj:galatea.dbm.inpaint.super_dbm.DenseMaxPool {
                    center: 0,
                        max_col_norm: 2.719156,
                        detector_layer_dim: %(layer1_dim)i,
                        pool_size: 1,
                        irange: 0.00893292525311,
                        layer_name: 'h1',
                        init_bias: -1.034643
               },
                !obj:galatea.dbm.inpaint.super_dbm.DenseMaxPool {
                    center: 0,
                        max_col_norm: 2.719156,
                        detector_layer_dim: %(layer2_dim)i,
                        pool_size: 1,
                        irange: 0.00893292525311,
                        layer_name: 'h2',
                        init_bias: -1.034643
               },
               !obj:galatea.dbm.inpaint.super_dbm.Softmax {
                    center: 0,
                        max_col_norm: 4.867584,
                        sparse_init: 0,
                        layer_name: 'c',
                        n_classes: 2
               }
              ]
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        monitoring_dataset : {
            # 'train': *train,
            raw_valid: !obj:pylearn2.datasets.icml07.Convex {
                                which_set: "valid",
                                one_hot: 1,
                            },
               },
        learning_rate: %(learning_rate)f,
        init_momentum: .5,
               cost: !obj:pylearn2.costs.cost.SumOfCosts {
                   costs :[
                      !obj:galatea.dbm.inpaint.super_inpaint.SuperInpaint {
                          l1_act_targets: [  0.160199, 0.049041, 0.049041, 0. ],
            l1_act_eps:     [  0.069507,  0.004643, 0.004643,  0. ],
            l1_act_coeffs:  [ 0.033942, 0.000023, 0.000023, 0.  ],
                          both_directions: 0,
                          noise: 0,
                           supervised: 1,
                           mask_gen: !obj:galatea.dbm.inpaint.super_inpaint.MaskGen {
                               drop_prob: 0.5,
                               balance: 0,
                               sync_channels: 0
                            }
                       }
                       ]
               },
               termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased
               {
                        channel_name: "raw_valid_err",
                        N: 100,
                        prop_decrease: 0.
               }
        },
    extensions: [
                !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
                        channel_name: "raw_valid_err",
                        save_path: %(save_path)s"best.pkl"
                },
                !obj:pylearn2.training_algorithms.sgd.MomentumAdjustor {
                    start: 1,
                    saturate: %(m_saturate)i,
                    final_momentum: %(final_momentum)f
                },
                !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {
                    start: 1,
                    saturate: %(lr_saturate)i,
                    decay_factor: %(decay_factor)f
                }
        ],
    save_path: %(save_path)s"last.pkl",
    save_freq : 2
}
